# 🧠 LLM Learning Notes | 大模型学习笔记

![Build Status](https://img.shields.io/badge/Status-Learning-green) ![Last Update](https://img.shields.io/badge/Last%20Update-Jan%202026-blue) ![Topic](https://img.shields.io/badge/Topic-Deep%20Learning%20%26%20LLM-orange)

> 记录我个人学习 Large Language Models (LLM) 的核心知识点、算法原理及工程实践笔记。
> 内容涵盖底层 GPU 架构、Transformer 核心组件、训练/推理优化技术、分布式并行以及前沿模型分析（如 Qwen, DeepSeek, MoE 等）。

---

## 📖 目录 (Table of Contents)

- [1. 基础架构与核心原理 (Architecture)](#1-基础架构与核心原理-architecture)
- [2. 训练与优化算法 (Training & Optimization)](#2-训练与优化算法-training--optimization)
- [3. 高效计算与显存优化 (Efficiency & Quantization)](#3-高效计算与显存优化-efficiency--quantization)
- [4. 分布式训练与工程 (Distributed Engineering)](#4-分布式训练与工程-distributed-engineering)
- [5. 模型架构分析 (Model Analysis)](#5-模型架构分析-model-analysis)
- [6. 对齐与强化学习 (Alignment & RLHF)](#6-对齐与强化学习-alignment--rlhf)
- [7. 推理与长上下文 (Inference & Long Context)](#7-推理与长上下文-inference--long-context)

---

## 🛠️ 关于笔记
本仓库笔记基于个人学习整理，参考了相关论文、官方文档及技术博客。如有错误，欢迎 Issue 指正。

## 📚 参考资料
*Wait to be updated...*

